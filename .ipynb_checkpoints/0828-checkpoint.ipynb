{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4639e401-d935-4833-8f96-ba65c1c1b275",
   "metadata": {},
   "source": [
    "## [모두의 딥러닝] 13장 모델 성능 검증하기 - K겹 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56e7eb3-7e3e-4ee3-9360-2b8473350772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/sonar3.csv', header=None)\n",
    "\n",
    "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:60]\n",
    "y = df.iloc[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066b0a03-d588-48b7-a29a-3ddf133b52c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\tiger-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7857 - loss: 0.5649 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\tiger-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9048 - loss: 0.4038 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\tiger-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7857 - loss: 0.9985 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\tiger-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8537 - loss: 0.4159 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\tiger-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8049 - loss: 0.7909 \n",
      "정확도: [0.7857142686843872, 0.9047619104385376, 0.7857142686843872, 0.8536585569381714, 0.8048780560493469]\n",
      "정확도 평균: 0.8269454121589661\n"
     ]
    }
   ],
   "source": [
    "#몇 겹으로 나눌 것인지를 정합니다. \n",
    "k=5\n",
    "\n",
    "#KFold 함수를 불러옵니다. 분할하기 전에 샘플이 치우치지 않도록 섞어 줍니다.\n",
    "kfold = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "#정확도가 채워질 빈 리스트를 준비합니다.\n",
    "acc_score = []\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential() #딥러닝 모델의 구조를 시작합니다.\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "#K겹 교차 검증을 이용해 k번의 학습을 실행합니다. \n",
    "for train_index , test_index in kfold.split(X):  # for문에 의해서 k번 반복합니다. spilt()에 의해 k개의 학습셋, 테스트셋으로 분리됩니다.\n",
    "    X_train , X_test = X.iloc[train_index,:], X.iloc[test_index,:]  \n",
    "    y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = model_fn()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history=model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=0) \n",
    "    \n",
    "    accuracy = model.evaluate(X_test, y_test)[1]  #정확도를 구합니다.\n",
    "    acc_score.append(accuracy)  #정확도 리스트에 저장합니다.\n",
    "\n",
    "#k번 실시된 정확도의 평균을 구합니다.\n",
    "avg_acc_score = sum(acc_score)/k\n",
    "\n",
    "#결과를 출력합니다.\n",
    "print('정확도:', acc_score)\n",
    "print('정확도 평균:', avg_acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374f0d1-6ff7-492e-8a1b-ff34d91595a0",
   "metadata": {},
   "source": [
    "## [모두의 딥러닝] 14장 모델 성능 향상시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2298881b-83c6-4d95-b946-b38500d6a2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 데이터를 미리 보겠습니다.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe121297-f71e-4c50-bbbf-881989af08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e59f679-fe17-493c-abc3-a9dd47654912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\tiger-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8173 - loss: 0.4240 - val_accuracy: 0.8392 - val_loss: 0.3556\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8571 - loss: 0.3070 - val_accuracy: 0.8954 - val_loss: 0.2710\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9120 - loss: 0.2470 - val_accuracy: 0.9146 - val_loss: 0.2468\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9335 - loss: 0.2272 - val_accuracy: 0.9146 - val_loss: 0.2458\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9379 - loss: 0.2151 - val_accuracy: 0.9223 - val_loss: 0.2258\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9392 - loss: 0.2051 - val_accuracy: 0.9223 - val_loss: 0.2181\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9389 - loss: 0.1973 - val_accuracy: 0.9262 - val_loss: 0.2150\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9400 - loss: 0.1896 - val_accuracy: 0.9185 - val_loss: 0.2076\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9376 - loss: 0.1856 - val_accuracy: 0.9208 - val_loss: 0.2053\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9397 - loss: 0.1822 - val_accuracy: 0.9238 - val_loss: 0.2011\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9402 - loss: 0.1804 - val_accuracy: 0.9269 - val_loss: 0.2083\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9405 - loss: 0.1788 - val_accuracy: 0.9262 - val_loss: 0.1971\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9423 - loss: 0.1747 - val_accuracy: 0.9300 - val_loss: 0.1942\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9435 - loss: 0.1718 - val_accuracy: 0.9277 - val_loss: 0.1925\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9441 - loss: 0.1699 - val_accuracy: 0.9308 - val_loss: 0.1927\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9448 - loss: 0.1688 - val_accuracy: 0.9323 - val_loss: 0.1877\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9443 - loss: 0.1676 - val_accuracy: 0.9308 - val_loss: 0.1999\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9428 - loss: 0.1677 - val_accuracy: 0.9338 - val_loss: 0.1854\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9464 - loss: 0.1652 - val_accuracy: 0.9369 - val_loss: 0.1818\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9461 - loss: 0.1613 - val_accuracy: 0.9377 - val_loss: 0.1807\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9471 - loss: 0.1588 - val_accuracy: 0.9354 - val_loss: 0.1788\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9479 - loss: 0.1574 - val_accuracy: 0.9354 - val_loss: 0.1800\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9474 - loss: 0.1584 - val_accuracy: 0.9369 - val_loss: 0.1776\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9489 - loss: 0.1581 - val_accuracy: 0.9362 - val_loss: 0.1792\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9482 - loss: 0.1509 - val_accuracy: 0.9369 - val_loss: 0.1738\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9479 - loss: 0.1507 - val_accuracy: 0.9362 - val_loss: 0.1761\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9487 - loss: 0.1501 - val_accuracy: 0.9377 - val_loss: 0.1708\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9500 - loss: 0.1481 - val_accuracy: 0.9377 - val_loss: 0.1682\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9512 - loss: 0.1460 - val_accuracy: 0.9392 - val_loss: 0.1715\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9482 - loss: 0.1481 - val_accuracy: 0.9369 - val_loss: 0.1694\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9489 - loss: 0.1462 - val_accuracy: 0.9377 - val_loss: 0.1809\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9492 - loss: 0.1478 - val_accuracy: 0.9377 - val_loss: 0.1677\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9518 - loss: 0.1410 - val_accuracy: 0.9392 - val_loss: 0.1651\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9502 - loss: 0.1396 - val_accuracy: 0.9377 - val_loss: 0.1637\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9515 - loss: 0.1377 - val_accuracy: 0.9385 - val_loss: 0.1616\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9507 - loss: 0.1368 - val_accuracy: 0.9400 - val_loss: 0.1627\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9520 - loss: 0.1356 - val_accuracy: 0.9377 - val_loss: 0.1592\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9505 - loss: 0.1345 - val_accuracy: 0.9400 - val_loss: 0.1616\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9512 - loss: 0.1325 - val_accuracy: 0.9385 - val_loss: 0.1560\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9528 - loss: 0.1311 - val_accuracy: 0.9408 - val_loss: 0.1563\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9523 - loss: 0.1302 - val_accuracy: 0.9408 - val_loss: 0.1550\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9523 - loss: 0.1293 - val_accuracy: 0.9392 - val_loss: 0.1559\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9520 - loss: 0.1288 - val_accuracy: 0.9438 - val_loss: 0.1546\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9525 - loss: 0.1284 - val_accuracy: 0.9423 - val_loss: 0.1511\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9538 - loss: 0.1268 - val_accuracy: 0.9446 - val_loss: 0.1546\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9518 - loss: 0.1260 - val_accuracy: 0.9408 - val_loss: 0.1501\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9538 - loss: 0.1252 - val_accuracy: 0.9431 - val_loss: 0.1590\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9554 - loss: 0.1243 - val_accuracy: 0.9408 - val_loss: 0.1495\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9536 - loss: 0.1250 - val_accuracy: 0.9423 - val_loss: 0.1488\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9551 - loss: 0.1211 - val_accuracy: 0.9485 - val_loss: 0.1454\n"
     ]
    }
   ],
   "source": [
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25) # 0.8 x 0.25 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa5fc35-e817-4d6f-bb9f-8d54d5d6cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1376 \n",
      "Test accuracy: 0.9561538696289062\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec8d130-4e36-4436-bd8e-517b3f51faa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\tiger-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0420cc6f-44e9-4592-86b1-cab1ed90f5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/model/all/01-0.7569.keras\n",
      "\n",
      "Epoch 2: saving model to ./data/model/all/02-0.8208.keras\n",
      "\n",
      "Epoch 3: saving model to ./data/model/all/03-0.8492.keras\n",
      "\n",
      "Epoch 4: saving model to ./data/model/all/04-0.8723.keras\n",
      "\n",
      "Epoch 5: saving model to ./data/model/all/05-0.8831.keras\n",
      "\n",
      "Epoch 6: saving model to ./data/model/all/06-0.8962.keras\n",
      "\n",
      "Epoch 7: saving model to ./data/model/all/07-0.9031.keras\n",
      "\n",
      "Epoch 8: saving model to ./data/model/all/08-0.9062.keras\n",
      "\n",
      "Epoch 9: saving model to ./data/model/all/09-0.9131.keras\n",
      "\n",
      "Epoch 10: saving model to ./data/model/all/10-0.9200.keras\n",
      "\n",
      "Epoch 11: saving model to ./data/model/all/11-0.9223.keras\n",
      "\n",
      "Epoch 12: saving model to ./data/model/all/12-0.9231.keras\n",
      "\n",
      "Epoch 13: saving model to ./data/model/all/13-0.9262.keras\n",
      "\n",
      "Epoch 14: saving model to ./data/model/all/14-0.9238.keras\n",
      "\n",
      "Epoch 15: saving model to ./data/model/all/15-0.9254.keras\n",
      "\n",
      "Epoch 16: saving model to ./data/model/all/16-0.9262.keras\n",
      "\n",
      "Epoch 17: saving model to ./data/model/all/17-0.9277.keras\n",
      "\n",
      "Epoch 18: saving model to ./data/model/all/18-0.9292.keras\n",
      "\n",
      "Epoch 19: saving model to ./data/model/all/19-0.9300.keras\n",
      "\n",
      "Epoch 20: saving model to ./data/model/all/20-0.9300.keras\n",
      "\n",
      "Epoch 21: saving model to ./data/model/all/21-0.9300.keras\n",
      "\n",
      "Epoch 22: saving model to ./data/model/all/22-0.9308.keras\n",
      "\n",
      "Epoch 23: saving model to ./data/model/all/23-0.9315.keras\n",
      "\n",
      "Epoch 24: saving model to ./data/model/all/24-0.9315.keras\n",
      "\n",
      "Epoch 25: saving model to ./data/model/all/25-0.9338.keras\n",
      "\n",
      "Epoch 26: saving model to ./data/model/all/26-0.9346.keras\n",
      "\n",
      "Epoch 27: saving model to ./data/model/all/27-0.9346.keras\n",
      "\n",
      "Epoch 28: saving model to ./data/model/all/28-0.9346.keras\n",
      "\n",
      "Epoch 29: saving model to ./data/model/all/29-0.9346.keras\n",
      "\n",
      "Epoch 30: saving model to ./data/model/all/30-0.9346.keras\n",
      "\n",
      "Epoch 31: saving model to ./data/model/all/31-0.9362.keras\n",
      "\n",
      "Epoch 32: saving model to ./data/model/all/32-0.9369.keras\n",
      "\n",
      "Epoch 33: saving model to ./data/model/all/33-0.9362.keras\n",
      "\n",
      "Epoch 34: saving model to ./data/model/all/34-0.9362.keras\n",
      "\n",
      "Epoch 35: saving model to ./data/model/all/35-0.9377.keras\n",
      "\n",
      "Epoch 36: saving model to ./data/model/all/36-0.9354.keras\n",
      "\n",
      "Epoch 37: saving model to ./data/model/all/37-0.9392.keras\n",
      "\n",
      "Epoch 38: saving model to ./data/model/all/38-0.9400.keras\n",
      "\n",
      "Epoch 39: saving model to ./data/model/all/39-0.9377.keras\n",
      "\n",
      "Epoch 40: saving model to ./data/model/all/40-0.9408.keras\n",
      "\n",
      "Epoch 41: saving model to ./data/model/all/41-0.9415.keras\n",
      "\n",
      "Epoch 42: saving model to ./data/model/all/42-0.9392.keras\n",
      "\n",
      "Epoch 43: saving model to ./data/model/all/43-0.9408.keras\n",
      "\n",
      "Epoch 44: saving model to ./data/model/all/44-0.9423.keras\n",
      "\n",
      "Epoch 45: saving model to ./data/model/all/45-0.9431.keras\n",
      "\n",
      "Epoch 46: saving model to ./data/model/all/46-0.9438.keras\n",
      "\n",
      "Epoch 47: saving model to ./data/model/all/47-0.9462.keras\n",
      "\n",
      "Epoch 48: saving model to ./data/model/all/48-0.9454.keras\n",
      "\n",
      "Epoch 49: saving model to ./data/model/all/49-0.9492.keras\n",
      "\n",
      "Epoch 50: saving model to ./data/model/all/50-0.9492.keras\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장의 조건을 설정합니다.\n",
    "modelpath=\"./data/model/all/{epoch:02d}-{val_accuracy:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "\n",
    "# 모델을 실행합니다. \n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e50b64f-f7ad-4a87-b1af-51e38f67c4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.1488 \n",
      "Test accuracy: 0.942307710647583\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8af8730-fc07-4a54-b35d-e09762e6eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 확인을 위한 긴 학습 (컴퓨터 환경에 따라 시간이 다소 걸릴수 있습니다)\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, verbose=0, validation_split=0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fdb564a-c46a-484a-8bab-27533bd057e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.955350</td>\n",
       "      <td>0.126945</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.136393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955863</td>\n",
       "      <td>0.125166</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.956890</td>\n",
       "      <td>0.121359</td>\n",
       "      <td>0.946923</td>\n",
       "      <td>0.131405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.957147</td>\n",
       "      <td>0.118726</td>\n",
       "      <td>0.947692</td>\n",
       "      <td>0.127113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.958686</td>\n",
       "      <td>0.116771</td>\n",
       "      <td>0.952308</td>\n",
       "      <td>0.128353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.988453</td>\n",
       "      <td>0.043107</td>\n",
       "      <td>0.991538</td>\n",
       "      <td>0.061657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.991532</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.088997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.990506</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.981538</td>\n",
       "      <td>0.081684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.993072</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>0.986154</td>\n",
       "      <td>0.073622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.992045</td>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.991538</td>\n",
       "      <td>0.061212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy      loss  val_accuracy  val_loss\n",
       "0     0.955350  0.126945      0.951538  0.136393\n",
       "1     0.955863  0.125166      0.953846  0.133484\n",
       "2     0.956890  0.121359      0.946923  0.131405\n",
       "3     0.957147  0.118726      0.947692  0.127113\n",
       "4     0.958686  0.116771      0.952308  0.128353\n",
       "...        ...       ...           ...       ...\n",
       "1995  0.988453  0.043107      0.991538  0.061657\n",
       "1996  0.991532  0.032210      0.985385  0.088997\n",
       "1997  0.990506  0.031754      0.981538  0.081684\n",
       "1998  0.993072  0.023188      0.986154  0.073622\n",
       "1999  0.992045  0.027726      0.991538  0.061212\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history에 저장된 학습 결과를 확인해 보겠습니다. \n",
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b249a1f9-78c5-4fbe-8a2a-2e39ac58ca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋(여기서는 검증셋)의 오차를 저장합니다.\n",
    "y_vloss=hist_df['val_loss']\n",
    "\n",
    "# y_loss에 학습셋의 오차를 저장합니다.\n",
    "y_loss=hist_df['loss']\n",
    "\n",
    "# x 값을 지정하고 테스트셋(검증셋)의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3bdf642-5d3e-4747-88a7-d1c79b8c55a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\tiger-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "#학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a1542b-6c41-4e13-81e9-320a02635bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.2658 - loss: 2.4931 - val_accuracy: 0.5731 - val_loss: 0.6820\n",
      "Epoch 2/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8396 - loss: 0.5875 - val_accuracy: 0.8969 - val_loss: 0.5208\n",
      "Epoch 3/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9140 - loss: 0.4635 - val_accuracy: 0.9300 - val_loss: 0.3768\n",
      "Epoch 4/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9243 - loss: 0.3508 - val_accuracy: 0.9285 - val_loss: 0.3003\n",
      "Epoch 5/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9253 - loss: 0.2887 - val_accuracy: 0.9246 - val_loss: 0.2587\n",
      "Epoch 6/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9266 - loss: 0.2520 - val_accuracy: 0.9308 - val_loss: 0.2318\n",
      "Epoch 7/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9274 - loss: 0.2305 - val_accuracy: 0.9277 - val_loss: 0.2173\n",
      "Epoch 8/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9261 - loss: 0.2182 - val_accuracy: 0.9308 - val_loss: 0.2087\n",
      "Epoch 9/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9292 - loss: 0.2105 - val_accuracy: 0.9323 - val_loss: 0.2029\n",
      "Epoch 10/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9294 - loss: 0.2046 - val_accuracy: 0.9323 - val_loss: 0.1982\n",
      "Epoch 11/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9317 - loss: 0.1979 - val_accuracy: 0.9354 - val_loss: 0.1922\n",
      "Epoch 12/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9323 - loss: 0.1934 - val_accuracy: 0.9392 - val_loss: 0.1887\n",
      "Epoch 13/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9328 - loss: 0.1910 - val_accuracy: 0.9346 - val_loss: 0.1869\n",
      "Epoch 14/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9338 - loss: 0.1882 - val_accuracy: 0.9377 - val_loss: 0.1848\n",
      "Epoch 15/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9333 - loss: 0.1862 - val_accuracy: 0.9354 - val_loss: 0.1830\n",
      "Epoch 16/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9346 - loss: 0.1840 - val_accuracy: 0.9377 - val_loss: 0.1811\n",
      "Epoch 17/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9353 - loss: 0.1820 - val_accuracy: 0.9369 - val_loss: 0.1795\n",
      "Epoch 18/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9361 - loss: 0.1801 - val_accuracy: 0.9400 - val_loss: 0.1773\n",
      "Epoch 19/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9358 - loss: 0.1782 - val_accuracy: 0.9400 - val_loss: 0.1758\n",
      "Epoch 20/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9374 - loss: 0.1761 - val_accuracy: 0.9415 - val_loss: 0.1737\n",
      "Epoch 21/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9384 - loss: 0.1746 - val_accuracy: 0.9408 - val_loss: 0.1728\n",
      "Epoch 22/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9389 - loss: 0.1730 - val_accuracy: 0.9408 - val_loss: 0.1708\n",
      "Epoch 23/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9369 - loss: 0.1712 - val_accuracy: 0.9431 - val_loss: 0.1677\n",
      "Epoch 24/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9394 - loss: 0.1688 - val_accuracy: 0.9408 - val_loss: 0.1680\n",
      "Epoch 25/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9394 - loss: 0.1670 - val_accuracy: 0.9446 - val_loss: 0.1637\n",
      "Epoch 26/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9418 - loss: 0.1641 - val_accuracy: 0.9423 - val_loss: 0.1629\n",
      "Epoch 27/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9420 - loss: 0.1632 - val_accuracy: 0.9469 - val_loss: 0.1596\n",
      "Epoch 28/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9423 - loss: 0.1611 - val_accuracy: 0.9469 - val_loss: 0.1582\n",
      "Epoch 29/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9441 - loss: 0.1587 - val_accuracy: 0.9469 - val_loss: 0.1572\n",
      "Epoch 30/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9443 - loss: 0.1577 - val_accuracy: 0.9508 - val_loss: 0.1541\n",
      "Epoch 31/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9466 - loss: 0.1552 - val_accuracy: 0.9469 - val_loss: 0.1552\n",
      "Epoch 32/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9456 - loss: 0.1537 - val_accuracy: 0.9508 - val_loss: 0.1519\n",
      "Epoch 33/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9479 - loss: 0.1518 - val_accuracy: 0.9508 - val_loss: 0.1517\n",
      "Epoch 34/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9487 - loss: 0.1509 - val_accuracy: 0.9515 - val_loss: 0.1489\n",
      "Epoch 35/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9489 - loss: 0.1497 - val_accuracy: 0.9523 - val_loss: 0.1471\n",
      "Epoch 36/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9487 - loss: 0.1470 - val_accuracy: 0.9500 - val_loss: 0.1500\n",
      "Epoch 37/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9500 - loss: 0.1464 - val_accuracy: 0.9523 - val_loss: 0.1441\n",
      "Epoch 38/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9512 - loss: 0.1444 - val_accuracy: 0.9500 - val_loss: 0.1473\n",
      "Epoch 39/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9510 - loss: 0.1440 - val_accuracy: 0.9531 - val_loss: 0.1422\n",
      "Epoch 40/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9520 - loss: 0.1421 - val_accuracy: 0.9538 - val_loss: 0.1410\n",
      "Epoch 41/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9525 - loss: 0.1408 - val_accuracy: 0.9538 - val_loss: 0.1407\n",
      "Epoch 42/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9541 - loss: 0.1392 - val_accuracy: 0.9554 - val_loss: 0.1392\n",
      "Epoch 43/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9520 - loss: 0.1382 - val_accuracy: 0.9538 - val_loss: 0.1370\n",
      "Epoch 44/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9533 - loss: 0.1371 - val_accuracy: 0.9546 - val_loss: 0.1364\n",
      "Epoch 45/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9533 - loss: 0.1370 - val_accuracy: 0.9546 - val_loss: 0.1370\n",
      "Epoch 46/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9543 - loss: 0.1338 - val_accuracy: 0.9546 - val_loss: 0.1341\n",
      "Epoch 47/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9541 - loss: 0.1327 - val_accuracy: 0.9554 - val_loss: 0.1319\n",
      "Epoch 48/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9541 - loss: 0.1311 - val_accuracy: 0.9554 - val_loss: 0.1337\n",
      "Epoch 49/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9546 - loss: 0.1304 - val_accuracy: 0.9562 - val_loss: 0.1308\n",
      "Epoch 50/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9543 - loss: 0.1297 - val_accuracy: 0.9562 - val_loss: 0.1300\n",
      "Epoch 51/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9551 - loss: 0.1281 - val_accuracy: 0.9554 - val_loss: 0.1307\n",
      "Epoch 52/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9548 - loss: 0.1278 - val_accuracy: 0.9538 - val_loss: 0.1280\n",
      "Epoch 53/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9554 - loss: 0.1265 - val_accuracy: 0.9562 - val_loss: 0.1274\n",
      "Epoch 54/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9561 - loss: 0.1254 - val_accuracy: 0.9577 - val_loss: 0.1287\n",
      "Epoch 55/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9551 - loss: 0.1250 - val_accuracy: 0.9546 - val_loss: 0.1249\n",
      "Epoch 56/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9554 - loss: 0.1237 - val_accuracy: 0.9554 - val_loss: 0.1248\n",
      "Epoch 57/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9571 - loss: 0.1231 - val_accuracy: 0.9577 - val_loss: 0.1283\n",
      "Epoch 58/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9577 - loss: 0.1217 - val_accuracy: 0.9562 - val_loss: 0.1241\n",
      "Epoch 59/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9584 - loss: 0.1196 - val_accuracy: 0.9569 - val_loss: 0.1254\n",
      "Epoch 60/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9566 - loss: 0.1190 - val_accuracy: 0.9554 - val_loss: 0.1216\n",
      "Epoch 61/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9569 - loss: 0.1181 - val_accuracy: 0.9546 - val_loss: 0.1207\n",
      "Epoch 62/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9595 - loss: 0.1185 - val_accuracy: 0.9554 - val_loss: 0.1335\n",
      "Epoch 63/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9584 - loss: 0.1191 - val_accuracy: 0.9554 - val_loss: 0.1195\n",
      "Epoch 64/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9589 - loss: 0.1149 - val_accuracy: 0.9546 - val_loss: 0.1189\n",
      "Epoch 65/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9592 - loss: 0.1133 - val_accuracy: 0.9562 - val_loss: 0.1194\n",
      "Epoch 66/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9587 - loss: 0.1121 - val_accuracy: 0.9546 - val_loss: 0.1180\n",
      "Epoch 67/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9597 - loss: 0.1111 - val_accuracy: 0.9562 - val_loss: 0.1209\n",
      "Epoch 68/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9582 - loss: 0.1110 - val_accuracy: 0.9554 - val_loss: 0.1162\n",
      "Epoch 69/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9589 - loss: 0.1100 - val_accuracy: 0.9569 - val_loss: 0.1154\n",
      "Epoch 70/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9615 - loss: 0.1095 - val_accuracy: 0.9569 - val_loss: 0.1181\n",
      "Epoch 71/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9623 - loss: 0.1067 - val_accuracy: 0.9569 - val_loss: 0.1136\n",
      "Epoch 72/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9607 - loss: 0.1063 - val_accuracy: 0.9562 - val_loss: 0.1132\n",
      "Epoch 73/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9618 - loss: 0.1049 - val_accuracy: 0.9577 - val_loss: 0.1124\n",
      "Epoch 74/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9623 - loss: 0.1040 - val_accuracy: 0.9577 - val_loss: 0.1112\n",
      "Epoch 75/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9620 - loss: 0.1050 - val_accuracy: 0.9569 - val_loss: 0.1267\n",
      "Epoch 76/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9623 - loss: 0.1036 - val_accuracy: 0.9654 - val_loss: 0.1121\n",
      "Epoch 77/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9620 - loss: 0.1052 - val_accuracy: 0.9600 - val_loss: 0.1077\n",
      "Epoch 78/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9651 - loss: 0.1021 - val_accuracy: 0.9600 - val_loss: 0.1116\n",
      "Epoch 79/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9656 - loss: 0.0982 - val_accuracy: 0.9631 - val_loss: 0.1065\n",
      "Epoch 80/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9674 - loss: 0.0959 - val_accuracy: 0.9662 - val_loss: 0.1035\n",
      "Epoch 81/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9679 - loss: 0.0953 - val_accuracy: 0.9669 - val_loss: 0.1027\n",
      "Epoch 82/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9690 - loss: 0.0939 - val_accuracy: 0.9685 - val_loss: 0.1020\n",
      "Epoch 83/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9705 - loss: 0.0929 - val_accuracy: 0.9692 - val_loss: 0.1020\n",
      "Epoch 84/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9690 - loss: 0.0937 - val_accuracy: 0.9677 - val_loss: 0.1003\n",
      "Epoch 85/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9715 - loss: 0.0915 - val_accuracy: 0.9700 - val_loss: 0.1011\n",
      "Epoch 86/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9715 - loss: 0.0905 - val_accuracy: 0.9708 - val_loss: 0.0983\n",
      "Epoch 87/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9702 - loss: 0.0896 - val_accuracy: 0.9692 - val_loss: 0.1025\n",
      "Epoch 88/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9697 - loss: 0.0901 - val_accuracy: 0.9715 - val_loss: 0.0984\n",
      "Epoch 89/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9700 - loss: 0.0890 - val_accuracy: 0.9692 - val_loss: 0.0963\n",
      "Epoch 90/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9705 - loss: 0.0888 - val_accuracy: 0.9723 - val_loss: 0.0956\n",
      "Epoch 91/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9705 - loss: 0.0878 - val_accuracy: 0.9708 - val_loss: 0.0987\n",
      "Epoch 92/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9715 - loss: 0.0875 - val_accuracy: 0.9723 - val_loss: 0.0972\n",
      "Epoch 93/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9672 - loss: 0.0915 - val_accuracy: 0.9677 - val_loss: 0.0948\n",
      "Epoch 94/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9715 - loss: 0.0872 - val_accuracy: 0.9685 - val_loss: 0.0937\n",
      "Epoch 95/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9733 - loss: 0.0848 - val_accuracy: 0.9715 - val_loss: 0.0948\n",
      "Epoch 96/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9720 - loss: 0.0840 - val_accuracy: 0.9715 - val_loss: 0.0936\n",
      "Epoch 97/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9736 - loss: 0.0830 - val_accuracy: 0.9731 - val_loss: 0.0948\n",
      "Epoch 98/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9736 - loss: 0.0829 - val_accuracy: 0.9762 - val_loss: 0.0921\n",
      "Epoch 99/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9741 - loss: 0.0816 - val_accuracy: 0.9738 - val_loss: 0.0911\n",
      "Epoch 100/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9746 - loss: 0.0810 - val_accuracy: 0.9723 - val_loss: 0.0925\n",
      "Epoch 101/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9728 - loss: 0.0811 - val_accuracy: 0.9692 - val_loss: 0.0913\n",
      "Epoch 102/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9728 - loss: 0.0868 - val_accuracy: 0.9731 - val_loss: 0.0907\n",
      "Epoch 103/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9725 - loss: 0.0810 - val_accuracy: 0.9692 - val_loss: 0.0985\n",
      "Epoch 104/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9743 - loss: 0.0804 - val_accuracy: 0.9738 - val_loss: 0.0889\n",
      "Epoch 105/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9754 - loss: 0.0790 - val_accuracy: 0.9692 - val_loss: 0.0888\n",
      "Epoch 106/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9733 - loss: 0.0814 - val_accuracy: 0.9723 - val_loss: 0.0963\n",
      "Epoch 107/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9733 - loss: 0.0803 - val_accuracy: 0.9731 - val_loss: 0.0923\n",
      "Epoch 108/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9761 - loss: 0.0773 - val_accuracy: 0.9754 - val_loss: 0.0876\n",
      "Epoch 109/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9751 - loss: 0.0769 - val_accuracy: 0.9723 - val_loss: 0.0875\n",
      "Epoch 110/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9751 - loss: 0.0772 - val_accuracy: 0.9738 - val_loss: 0.0874\n",
      "Epoch 111/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9764 - loss: 0.0754 - val_accuracy: 0.9746 - val_loss: 0.0893\n",
      "Epoch 112/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9759 - loss: 0.0755 - val_accuracy: 0.9762 - val_loss: 0.0877\n",
      "Epoch 113/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9769 - loss: 0.0741 - val_accuracy: 0.9738 - val_loss: 0.0859\n",
      "Epoch 114/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9759 - loss: 0.0765 - val_accuracy: 0.9746 - val_loss: 0.0900\n",
      "Epoch 115/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9759 - loss: 0.0747 - val_accuracy: 0.9738 - val_loss: 0.0933\n",
      "Epoch 116/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9743 - loss: 0.0750 - val_accuracy: 0.9731 - val_loss: 0.0838\n",
      "Epoch 117/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9779 - loss: 0.0730 - val_accuracy: 0.9754 - val_loss: 0.0847\n",
      "Epoch 118/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9777 - loss: 0.0717 - val_accuracy: 0.9769 - val_loss: 0.0864\n",
      "Epoch 119/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9772 - loss: 0.0716 - val_accuracy: 0.9738 - val_loss: 0.0829\n",
      "Epoch 120/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9766 - loss: 0.0713 - val_accuracy: 0.9769 - val_loss: 0.0840\n",
      "Epoch 121/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9769 - loss: 0.0717 - val_accuracy: 0.9777 - val_loss: 0.0846\n",
      "Epoch 122/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9779 - loss: 0.0704 - val_accuracy: 0.9762 - val_loss: 0.0831\n",
      "Epoch 123/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9777 - loss: 0.0702 - val_accuracy: 0.9762 - val_loss: 0.0813\n",
      "Epoch 124/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9782 - loss: 0.0691 - val_accuracy: 0.9746 - val_loss: 0.0818\n",
      "Epoch 125/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9787 - loss: 0.0692 - val_accuracy: 0.9785 - val_loss: 0.0826\n",
      "Epoch 126/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9779 - loss: 0.0682 - val_accuracy: 0.9769 - val_loss: 0.0808\n",
      "Epoch 127/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9784 - loss: 0.0677 - val_accuracy: 0.9785 - val_loss: 0.0819\n",
      "Epoch 128/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9784 - loss: 0.0675 - val_accuracy: 0.9762 - val_loss: 0.0803\n",
      "Epoch 129/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9779 - loss: 0.0674 - val_accuracy: 0.9777 - val_loss: 0.0826\n",
      "Epoch 130/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9774 - loss: 0.0679 - val_accuracy: 0.9769 - val_loss: 0.0798\n",
      "Epoch 131/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9782 - loss: 0.0686 - val_accuracy: 0.9762 - val_loss: 0.0825\n",
      "Epoch 132/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9779 - loss: 0.0706 - val_accuracy: 0.9777 - val_loss: 0.0818\n",
      "Epoch 133/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9779 - loss: 0.0667 - val_accuracy: 0.9777 - val_loss: 0.0809\n",
      "Epoch 134/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9784 - loss: 0.0648 - val_accuracy: 0.9769 - val_loss: 0.0795\n",
      "Epoch 135/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9790 - loss: 0.0647 - val_accuracy: 0.9777 - val_loss: 0.0805\n",
      "Epoch 136/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9790 - loss: 0.0646 - val_accuracy: 0.9777 - val_loss: 0.0799\n",
      "Epoch 137/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9782 - loss: 0.0651 - val_accuracy: 0.9777 - val_loss: 0.0774\n",
      "Epoch 138/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9795 - loss: 0.0636 - val_accuracy: 0.9769 - val_loss: 0.0786\n",
      "Epoch 139/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9797 - loss: 0.0639 - val_accuracy: 0.9777 - val_loss: 0.0769\n",
      "Epoch 140/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9795 - loss: 0.0634 - val_accuracy: 0.9777 - val_loss: 0.0779\n",
      "Epoch 141/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9795 - loss: 0.0625 - val_accuracy: 0.9792 - val_loss: 0.0808\n",
      "Epoch 142/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9795 - loss: 0.0655 - val_accuracy: 0.9777 - val_loss: 0.0797\n",
      "Epoch 143/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9802 - loss: 0.0625 - val_accuracy: 0.9769 - val_loss: 0.0779\n",
      "Epoch 144/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9800 - loss: 0.0639 - val_accuracy: 0.9785 - val_loss: 0.0767\n",
      "Epoch 145/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9800 - loss: 0.0655 - val_accuracy: 0.9792 - val_loss: 0.0785\n",
      "Epoch 146/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9795 - loss: 0.0636 - val_accuracy: 0.9769 - val_loss: 0.0850\n",
      "Epoch 147/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9782 - loss: 0.0645 - val_accuracy: 0.9769 - val_loss: 0.0848\n",
      "Epoch 148/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9787 - loss: 0.0641 - val_accuracy: 0.9785 - val_loss: 0.0755\n",
      "Epoch 149/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9808 - loss: 0.0615 - val_accuracy: 0.9808 - val_loss: 0.0731\n",
      "Epoch 150/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9795 - loss: 0.0610 - val_accuracy: 0.9792 - val_loss: 0.0757\n",
      "Epoch 151/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9800 - loss: 0.0599 - val_accuracy: 0.9792 - val_loss: 0.0744\n",
      "Epoch 152/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9802 - loss: 0.0607 - val_accuracy: 0.9800 - val_loss: 0.0738\n",
      "Epoch 153/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9800 - loss: 0.0592 - val_accuracy: 0.9792 - val_loss: 0.0821\n",
      "Epoch 154/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9808 - loss: 0.0621 - val_accuracy: 0.9800 - val_loss: 0.0799\n",
      "Epoch 155/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9792 - loss: 0.0623 - val_accuracy: 0.9792 - val_loss: 0.0731\n",
      "Epoch 156/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9787 - loss: 0.0607 - val_accuracy: 0.9792 - val_loss: 0.0728\n",
      "Epoch 157/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9810 - loss: 0.0589 - val_accuracy: 0.9800 - val_loss: 0.0761\n",
      "Epoch 158/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9805 - loss: 0.0590 - val_accuracy: 0.9808 - val_loss: 0.0777\n",
      "Epoch 159/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9805 - loss: 0.0581 - val_accuracy: 0.9815 - val_loss: 0.0744\n",
      "Epoch 160/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9810 - loss: 0.0576 - val_accuracy: 0.9785 - val_loss: 0.0727\n",
      "Epoch 161/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9810 - loss: 0.0604 - val_accuracy: 0.9808 - val_loss: 0.0755\n",
      "Epoch 162/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9808 - loss: 0.0577 - val_accuracy: 0.9815 - val_loss: 0.0762\n",
      "Epoch 163/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9815 - loss: 0.0574 - val_accuracy: 0.9800 - val_loss: 0.0775\n",
      "Epoch 164/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9823 - loss: 0.0577 - val_accuracy: 0.9792 - val_loss: 0.0712\n",
      "Epoch 165/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9810 - loss: 0.0572 - val_accuracy: 0.9792 - val_loss: 0.0711\n",
      "Epoch 166/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0571 - val_accuracy: 0.9800 - val_loss: 0.0727\n",
      "Epoch 167/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0556 - val_accuracy: 0.9823 - val_loss: 0.0742\n",
      "Epoch 168/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9815 - loss: 0.0562 - val_accuracy: 0.9800 - val_loss: 0.0712\n",
      "Epoch 169/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9813 - loss: 0.0561 - val_accuracy: 0.9792 - val_loss: 0.0714\n",
      "Epoch 170/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9820 - loss: 0.0549 - val_accuracy: 0.9823 - val_loss: 0.0717\n",
      "Epoch 171/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9815 - loss: 0.0547 - val_accuracy: 0.9800 - val_loss: 0.0696\n",
      "Epoch 172/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9810 - loss: 0.0574 - val_accuracy: 0.9823 - val_loss: 0.0711\n",
      "Epoch 173/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9818 - loss: 0.0560 - val_accuracy: 0.9815 - val_loss: 0.0776\n",
      "Epoch 174/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9818 - loss: 0.0551 - val_accuracy: 0.9823 - val_loss: 0.0704\n",
      "Epoch 175/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9810 - loss: 0.0542 - val_accuracy: 0.9800 - val_loss: 0.0693\n",
      "Epoch 176/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9818 - loss: 0.0545 - val_accuracy: 0.9815 - val_loss: 0.0742\n",
      "Epoch 177/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9820 - loss: 0.0540 - val_accuracy: 0.9815 - val_loss: 0.0703\n",
      "Epoch 178/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9818 - loss: 0.0536 - val_accuracy: 0.9815 - val_loss: 0.0720\n",
      "Epoch 179/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9828 - loss: 0.0533 - val_accuracy: 0.9815 - val_loss: 0.0733\n",
      "Epoch 180/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9808 - loss: 0.0550 - val_accuracy: 0.9792 - val_loss: 0.0690\n",
      "Epoch 181/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9820 - loss: 0.0528 - val_accuracy: 0.9831 - val_loss: 0.0706\n",
      "Epoch 182/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9826 - loss: 0.0531 - val_accuracy: 0.9823 - val_loss: 0.0720\n",
      "Epoch 183/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9818 - loss: 0.0532 - val_accuracy: 0.9815 - val_loss: 0.0763\n",
      "Epoch 184/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9818 - loss: 0.0545 - val_accuracy: 0.9823 - val_loss: 0.0701\n",
      "Epoch 185/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9818 - loss: 0.0524 - val_accuracy: 0.9800 - val_loss: 0.0685\n",
      "Epoch 186/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0528 - val_accuracy: 0.9800 - val_loss: 0.0676\n",
      "Epoch 187/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9820 - loss: 0.0536 - val_accuracy: 0.9800 - val_loss: 0.0682\n",
      "Epoch 188/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9838 - loss: 0.0544 - val_accuracy: 0.9815 - val_loss: 0.0716\n",
      "Epoch 189/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9826 - loss: 0.0520 - val_accuracy: 0.9815 - val_loss: 0.0719\n",
      "Epoch 190/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9826 - loss: 0.0516 - val_accuracy: 0.9800 - val_loss: 0.0670\n",
      "Epoch 191/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9851 - loss: 0.0510 - val_accuracy: 0.9823 - val_loss: 0.0719\n",
      "Epoch 192/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9836 - loss: 0.0522 - val_accuracy: 0.9823 - val_loss: 0.0725\n",
      "Epoch 193/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9833 - loss: 0.0522 - val_accuracy: 0.9808 - val_loss: 0.0755\n",
      "Epoch 194/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.0540 - val_accuracy: 0.9831 - val_loss: 0.0710\n",
      "Epoch 195/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9831 - loss: 0.0520 - val_accuracy: 0.9792 - val_loss: 0.0680\n",
      "Epoch 196/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9828 - loss: 0.0508 - val_accuracy: 0.9815 - val_loss: 0.0681\n",
      "Epoch 197/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9828 - loss: 0.0525 - val_accuracy: 0.9808 - val_loss: 0.0725\n",
      "Epoch 198/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9828 - loss: 0.0505 - val_accuracy: 0.9831 - val_loss: 0.0704\n",
      "Epoch 199/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9836 - loss: 0.0525 - val_accuracy: 0.9808 - val_loss: 0.0699\n",
      "Epoch 200/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9836 - loss: 0.0518 - val_accuracy: 0.9792 - val_loss: 0.0662\n",
      "Epoch 201/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9833 - loss: 0.0501 - val_accuracy: 0.9831 - val_loss: 0.0681\n",
      "Epoch 202/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9841 - loss: 0.0501 - val_accuracy: 0.9808 - val_loss: 0.0664\n",
      "Epoch 203/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9836 - loss: 0.0495 - val_accuracy: 0.9815 - val_loss: 0.0693\n",
      "Epoch 204/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9831 - loss: 0.0501 - val_accuracy: 0.9792 - val_loss: 0.0680\n",
      "Epoch 205/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9836 - loss: 0.0496 - val_accuracy: 0.9823 - val_loss: 0.0678\n",
      "Epoch 206/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9833 - loss: 0.0489 - val_accuracy: 0.9831 - val_loss: 0.0673\n",
      "Epoch 207/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9828 - loss: 0.0490 - val_accuracy: 0.9823 - val_loss: 0.0677\n",
      "Epoch 208/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9828 - loss: 0.0489 - val_accuracy: 0.9815 - val_loss: 0.0659\n",
      "Epoch 209/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9854 - loss: 0.0491 - val_accuracy: 0.9815 - val_loss: 0.0734\n",
      "Epoch 210/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9846 - loss: 0.0489 - val_accuracy: 0.9815 - val_loss: 0.0647\n",
      "Epoch 211/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9833 - loss: 0.0506 - val_accuracy: 0.9792 - val_loss: 0.0713\n",
      "Epoch 212/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9838 - loss: 0.0531 - val_accuracy: 0.9823 - val_loss: 0.0680\n",
      "Epoch 213/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9851 - loss: 0.0500 - val_accuracy: 0.9823 - val_loss: 0.0688\n",
      "Epoch 214/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9843 - loss: 0.0492 - val_accuracy: 0.9815 - val_loss: 0.0716\n",
      "Epoch 215/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9856 - loss: 0.0483 - val_accuracy: 0.9815 - val_loss: 0.0651\n",
      "Epoch 216/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9836 - loss: 0.0496 - val_accuracy: 0.9792 - val_loss: 0.0650\n",
      "Epoch 217/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9836 - loss: 0.0500 - val_accuracy: 0.9815 - val_loss: 0.0654\n",
      "Epoch 218/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9836 - loss: 0.0481 - val_accuracy: 0.9823 - val_loss: 0.0650\n",
      "Epoch 219/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9854 - loss: 0.0476 - val_accuracy: 0.9823 - val_loss: 0.0668\n",
      "Epoch 220/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9838 - loss: 0.0473 - val_accuracy: 0.9815 - val_loss: 0.0659\n",
      "Epoch 221/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9849 - loss: 0.0472 - val_accuracy: 0.9815 - val_loss: 0.0712\n",
      "Epoch 222/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9861 - loss: 0.0491 - val_accuracy: 0.9823 - val_loss: 0.0688\n",
      "Epoch 223/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9823 - loss: 0.0545 - val_accuracy: 0.9815 - val_loss: 0.0656\n",
      "Epoch 224/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9826 - loss: 0.0535 - val_accuracy: 0.9792 - val_loss: 0.0665\n",
      "Epoch 225/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9851 - loss: 0.0490 - val_accuracy: 0.9815 - val_loss: 0.0639\n",
      "Epoch 226/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9841 - loss: 0.0512 - val_accuracy: 0.9823 - val_loss: 0.0673\n",
      "Epoch 227/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9861 - loss: 0.0468 - val_accuracy: 0.9823 - val_loss: 0.0662\n",
      "Epoch 228/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9838 - loss: 0.0479 - val_accuracy: 0.9838 - val_loss: 0.0635\n",
      "Epoch 229/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9843 - loss: 0.0487 - val_accuracy: 0.9815 - val_loss: 0.0631\n",
      "Epoch 230/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9851 - loss: 0.0492 - val_accuracy: 0.9815 - val_loss: 0.0644\n",
      "Epoch 231/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9849 - loss: 0.0485 - val_accuracy: 0.9823 - val_loss: 0.0679\n",
      "Epoch 232/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9859 - loss: 0.0460 - val_accuracy: 0.9815 - val_loss: 0.0664\n",
      "Epoch 233/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9846 - loss: 0.0459 - val_accuracy: 0.9808 - val_loss: 0.0655\n",
      "Epoch 234/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9849 - loss: 0.0462 - val_accuracy: 0.9808 - val_loss: 0.0669\n",
      "Epoch 235/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9854 - loss: 0.0457 - val_accuracy: 0.9808 - val_loss: 0.0641\n",
      "Epoch 236/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9856 - loss: 0.0456 - val_accuracy: 0.9815 - val_loss: 0.0654\n",
      "Epoch 237/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9849 - loss: 0.0454 - val_accuracy: 0.9831 - val_loss: 0.0633\n",
      "Epoch 238/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9851 - loss: 0.0465 - val_accuracy: 0.9831 - val_loss: 0.0633\n",
      "Epoch 239/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9854 - loss: 0.0469 - val_accuracy: 0.9823 - val_loss: 0.0633\n",
      "Epoch 240/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9861 - loss: 0.0468 - val_accuracy: 0.9815 - val_loss: 0.0676\n",
      "Epoch 241/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9856 - loss: 0.0457 - val_accuracy: 0.9815 - val_loss: 0.0682\n",
      "Epoch 242/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9846 - loss: 0.0459 - val_accuracy: 0.9815 - val_loss: 0.0659\n",
      "Epoch 243/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.0449 - val_accuracy: 0.9815 - val_loss: 0.0654\n",
      "Epoch 244/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9849 - loss: 0.0453 - val_accuracy: 0.9815 - val_loss: 0.0650\n",
      "Epoch 245/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9841 - loss: 0.0458 - val_accuracy: 0.9815 - val_loss: 0.0660\n",
      "Epoch 246/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9846 - loss: 0.0457 - val_accuracy: 0.9815 - val_loss: 0.0677\n",
      "Epoch 247/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9854 - loss: 0.0453 - val_accuracy: 0.9815 - val_loss: 0.0664\n",
      "Epoch 248/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9864 - loss: 0.0452 - val_accuracy: 0.9815 - val_loss: 0.0736\n",
      "Epoch 249/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9841 - loss: 0.0491 - val_accuracy: 0.9815 - val_loss: 0.0634\n"
     ]
    }
   ],
   "source": [
    "# 학습이 언제 자동 중단 될지를 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "#최적화 모델이 저장될 폴더와 모델의 이름을 정합니다.\n",
    "modelpath=\"./data/model/Ch14-4-bestmodel.keras\"\n",
    "\n",
    "# 최적화 모델을 업데이트하고 저장합니다.\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "#모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback,checkpointer]) #verbose=1 진행 화면 출력, verbose=0 진행 화면 출력 안함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd39fef-6e4f-44f9-9460-d5e22904449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.0829\n",
      "Test accuracy: 0.9784615635871887\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
